@article{Braman10,
title = {Third-Order Tensors as Linear Operators on a Space of Matrices},
journal = {Linear Algebra and its Applications},
volume = {433},
number = {7},
pages = {1241-1253},
year = {2010},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2010.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S0024379510002934},
author = {Karen Braman},
keywords = {Multilinear algebra, Tensor decomposition, Diagonalization},
abstract = {A recently proposed tensor-tensor multiplication (M.E. Kilmer, C.D. Martin, L. Perrone, A Third-Order Generalization of the Matrix SVD as a Product of Third-Order Tensors, Tech. Rep. TR-2008-4, Tufts University, October 2008) opens up new avenues to understanding the action of n×n×n tensors on a space of n×n matrices. In particular it emphasizes the need to understand the space of objects upon which tensors act. This paper defines a free module and shows that every linear transformation on that module can be represented by tensor multiplication. In addition, it presents a generalization of ideas of eigenvalue and eigenvector to the space of n×n×n tensors.}
}

@article{KilmerMartin11,
title = {Factorization strategies for third-order tensors},
journal = {Linear Algebra and its Applications},
volume = {435},
number = {3},
pages = {641-658},
year = {2011},
note = {Special Issue: Dedication to Pete Stewart on the occasion of his 70th birthday},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2010.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0024379510004830},
author = {Misha E. Kilmer and Carla D. Martin},
keywords = {Multilinear algebra, Tensor decomposition, Singular value decomposition, Multidimensional arrays},
abstract = {Operations with tensors, or multiway arrays, have become increasingly prevalent in recent years. Traditionally, tensors are represented or decomposed as a sum of rank-1 outer products using either the CANDECOMP/PARAFAC (CP) or the Tucker models, or some variation thereof. Such decompositions are motivated by specific applications where the goal is to find an approximate such representation for a given multiway array. The specifics of the approximate representation (such as how many terms to use in the sum, orthogonality constraints, etc.) depend on the application. In this paper, we explore an alternate representation of tensors which shows promise with respect to the tensor approximation problem. Reminiscent of matrix factorizations, we present a new factorization of a tensor as a product of tensors. To derive the new factorization, we define a closed multiplication operation between tensors. A major motivation for considering this new type of tensor multiplication is to devise new types of factorizations for tensors which can then be used in applications. Specifically, this new multiplication allows us to introduce concepts such as tensor transpose, inverse, and identity, which lead to the notion of an orthogonal tensor. The multiplication also gives rise to a linear operator, and the null space of the resulting operator is identified. We extend the concept of outer products of vectors to outer products of matrices. All derivations are presented for third-order tensors. However, they can be easily extended to the order-p (p>3) case. We conclude with an application in image deblurring.}
}

@article{article,
author = {Kilmer, Misha and Braman, Karen and Hao, Ning and Hoover, Randy},
year = {2013},
month = {01},
pages = {},
title = {Third-Order Tensors as Operators on Matrices: A Theoretical and Computational Framework with Applications in Imaging},
volume = {34},
journal = {SIAM Journal on Matrix Analysis and Applications},
doi = {10.1137/110837711}
}



@article {
author = {El Guide, Mohamed and El Ichi, Alaa and Jbilou, Khalide},
title = {Discrete cosine transform LSQR methods for multidimensional ill-posed problems},
journal = {Journal of Mathematical Modeling},
volume = {10},
number = {1},
pages = {21-37},
year  = {2022},
publisher = {University of Guilan},
issn = {2345-394X}, 
eissn = {2382-9869}, 
doi = {10.22124/jmm.2021.19303.1659},
abstract = {We propose new tensor Krylov subspace methods  for ill-posed linear tensor problems such as color or video image restoration. Those methods are based on the tensor-tensor discrete cosine transform that gives fast tensor-tensor product computations. In particular, we will focus on the tensor discrete cosine versions of GMRES, Golub-Kahan bidiagonalisation and LSQR methods. The presented numerical tests show that the methods are very fast and give good accuracies when solving some linear tensor ill-posed problems.},
keywords = {Discrete cosine product,Golub-Kahan bidiagonalisation,GMRES,LSQR,tensor Krylov subspaces},	
url = {https://jmm.guilan.ac.ir/article_4817.html},
eprint = {https://jmm.guilan.ac.ir/article_4817_85dd931b01c788d42aa9bbb266512191.pdf}
}

