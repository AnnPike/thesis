#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
theorems-ams
theorems-ams-extended
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 3.5cm
\rightmargin 2.5cm
\bottommargin 3.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Notation*
Calligraphic latin 
\begin_inset Formula ${\cal A},{\cal B},{\cal C}$
\end_inset


\begin_inset Formula $\in\mathbb{R}^{m\times p\times n}$
\end_inset

 etc are 3-mode tensors.
 Overlined big latin letters
\begin_inset Formula $\overline{B},\overline{E},\overline{R}\in\mathbb{R}^{m\times1\times n}$
\end_inset

 are 
\emph on
vector tensors, 
\emph default
i.e.
 tensors in which the second dimension is 1.
 Greek small letters 
\begin_inset Formula $\alpha,\lambda,\beta\in\mathbb{R}^{1\times1\times n}$
\end_inset

 are tuple scalars (meaning the first and second dimentions are equal to
 1), and small latin letters 
\begin_inset Formula $a,b,c\in\mathbb{R}$
\end_inset

 are scalars.
 The notation of 
\begin_inset Formula $\star_{M}$
\end_inset

 is simplified to 
\begin_inset Formula $\star$
\end_inset

.
 
\color red
TODO: add notation for inverse facewise.
\end_layout

\begin_layout Section*
The Problem.
\end_layout

\begin_layout Problem
Given 
\begin_inset Formula $\mathcal{A}\in\mathbb{R}^{m\times p\times n}$
\end_inset

, 
\begin_inset Formula $\overline{B}\in\mathbb{R}^{m\times1\times n}$
\end_inset

, find 
\begin_inset Formula 
\[
\overline{X}^{\star}=\arg\min_{x\in\mathbb{R}^{p\times1\times n}}\|\mathcal{A}\star\overline{X}-\overline{B}\|_{F}
\]

\end_inset


\end_layout

\begin_layout Section*
Direct Methods.
\end_layout

\begin_layout Standard

\series bold
QR decomposition:
\series default
 
\begin_inset Formula $\mathcal{A}=\mathcal{Q}\star R$
\end_inset

 where 
\begin_inset Formula $\mathcal{Q}\in\mathbb{R}^{m\times p\times n}$
\end_inset

 orthogonal (
\begin_inset Formula $\mathcal{Q}^{T}\star\mathcal{Q}=\mathcal{I}_{p\times p\times n}$
\end_inset

), 
\begin_inset Formula $\mathcal{R}\in\mathbb{R}^{p\times p\times n}$
\end_inset

 each frontal slices is triangular.
 Such a decomposition exists (need to see how much this definition is new,
 have been done for general 
\begin_inset Formula $M$
\end_inset

, etc.
 :defined in
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "KilmerMartin11"
literal "false"

\end_inset

 for fft).
\end_layout

\begin_layout Standard
Define, 
\begin_inset Formula $\mathcal{R}^{-1}\coloneqq(\mathcal{R}\times_{3}M)^{-1(\Delta)}\times_{3}M^{-1}$
\end_inset

.
 This is really the inverse: 
\begin_inset Formula 
\[
\mathcal{R}\star_{M}\mathcal{R}^{-1}=((\mathcal{R}\times_{3}M)\Delta(\mathcal{R}^{-1}\times_{3}M))\times M^{-1}=((\mathcal{R}\times_{3}M)\Delta((\mathcal{R}\times_{3}M)^{-1(\Delta)})\times M^{-1}=I^{\Delta}\times M^{-1}=\mathcal{I}_{p\times p\times n}.
\]

\end_inset


\end_layout

\begin_layout Proposition
We have 
\begin_inset Formula $\overline{X}^{\star}=\mathcal{R}^{-1}\star\mathcal{Q}^{T}\star\overline{B}$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula $\mathcal{A}\star\overline{X}=\overline{B}\Rightarrow\mathcal{Q}\star\mathcal{R}\star\overline{X}=\overline{B}\Longrightarrow\mathcal{R}\star\overline{X}=\mathcal{Q}^{T}\star\overline{B}\Rightarrow\mathcal{\hat{R}}\Delta\hat{\overline{X}}=\hat{\mathcal{Q}}^{T}\Delta\hat{\overline{B}}$
\end_inset

.
 Obvious that 
\begin_inset Formula $\hat{\mathcal{R}}$
\end_inset

 is f-triangular, then each frontal slice can be solved by backsubstitution
 
\begin_inset Formula $\hat{\overline{X}}=\hat{\mathcal{R}}^{-1(\Delta)}\Delta\hat{\mathcal{Q}}^{T}\Delta\hat{\overline{B}}\Rightarrow\hat{\overline{X}}^{\star}=\mathcal{R}^{-1}\star_{M}\mathcal{Q}^{T}\star_{M}\overline{B}$
\end_inset


\end_layout

\begin_layout Paragraph
Normal equations:
\end_layout

\begin_layout Conjecture
\begin_inset Formula $\overline{X}^{\star}$
\end_inset

 is the unique solution to the equation 
\begin_inset Formula $\mathcal{A}^{T}\star_{M}\mathcal{A}\star_{M}\overline{X}=\mathcal{A}^{T}\star_{M}\overline{B}$
\end_inset

 (2)
\end_layout

\begin_layout Proof
\begin_inset Formula $\overline{R}=\mathcal{A}\star\overline{X}^{\star}-\overline{B}$
\end_inset

, let's prove that 
\begin_inset Formula $\mathcal{A}^{T}\star\overline{R}=0$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\overline{R}=\overline{R}_{\mathcal{A}}+\overline{R}_{\perp\mathcal{A}}$
\end_inset

, 
\begin_inset Formula $\overline{R}_{\mathcal{A}}\bell\in range(\mathcal{A})$
\end_inset

, 
\begin_inset Formula $\overline{R}_{\perp\mathcal{A}}\bell\in null(\mathcal{A}^{T})$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\overline{R}_{\mathcal{A}}=\mathcal{A}\star\overline{Z}$
\end_inset

, taking 
\begin_inset Formula $\overline{X}'=\overline{X}^{\star}-\overline{Z},$
\end_inset

we have
\end_layout

\begin_layout Proof
\begin_inset Formula $||\mathcal{A}\star\overline{X}'-b||=||\mathcal{A}\star(\overline{X}^{\star}-\overline{Z})-\overline{B}||=||\mathcal{A}\star\overline{X}^{\star}-\overline{B}-\mathcal{A}\star\overline{Z}||=||\overline{R}-\mathcal{A}\star\overline{Z}||=||\overline{R}_{\perp\mathcal{A}}||\leq||\overline{R}||$
\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $||\overline{R}||$
\end_inset

is minimal by the assumption, 
\begin_inset Formula $\overline{R}_{\mathcal{A}}=0\Rightarrow\overline{R}\in null(\mathcal{A}^{T})$
\end_inset


\end_layout

\begin_layout Proof
then 
\begin_inset Formula $\mathcal{A}^{T}\star_{M}\overline{R}=\mathcal{A}^{T}\star_{M}\mathcal{A}\star_{M}\overline{X}^{\star}-\mathcal{A}^{T}\star_{M}\overline{B}$
\end_inset


\begin_inset Formula $\Longrightarrow\mathcal{A}^{T}\star_{M}\mathcal{A}\star_{M}x^{\star}=\mathcal{A}\star_{M}\overline{B}$
\end_inset


\end_layout

\begin_layout Section*
Iterative Methods.
\end_layout

\begin_layout Subsection*
CG on the Normal Equations
\end_layout

\begin_layout Standard
We want to solve 
\begin_inset Formula $\mathcal{A}^{T}\star_{M}\mathcal{A}\star_{M}\overline{X}=\mathcal{A}^{T}\star_{M}\overline{B}$
\end_inset

 using tensor-CG.
 
\end_layout

\begin_layout Definition
A tensor 
\begin_inset Formula $\mathcal{A}\in\mathbb{R}^{p\times p\times n}$
\end_inset

 is symmetric positive definite if every frontal slices of 
\begin_inset Formula $\hat{\mathcal{A}}=\mathcal{A}\times_{3}M$
\end_inset

 is symmetric psd.
 
\color red
QUESTION: if we have a 
\begin_inset Formula $\overline{X}$
\end_inset

, what does this imply on 
\begin_inset Formula $\overline{X}^{T}\star{\cal A}\star\overline{X}$
\end_inset

?
\end_layout

\begin_layout Standard

\series bold
Claim:
\series default
 
\begin_inset Formula $(\mathcal{A}^{T}\star_{M}\mathcal{A})$
\end_inset

 is symmetric positive definite tensor.
\end_layout

\begin_layout Standard
Easy to see that since 
\begin_inset Formula $\mathcal{A}\times_{3}M$
\end_inset

 operate on tubes, 
\begin_inset Formula $(A^{T}\times_{3}M)=(A\times_{3}M)^{T}$
\end_inset


\end_layout

\begin_layout Standard
Than following 
\begin_inset Formula $(\mathcal{A}^{T}\star_{M}\mathcal{A})\times_{3}M=(\mathcal{A}^{T}\times_{3}M)\Delta(\mathcal{A}\times_{3}M)=(\mathcal{A}\times_{3}M)^{T}\Delta(\mathcal{A}\times_{3}M)={\cal \hat{A}^{T}}\Delta\hat{{\cal A}}$
\end_inset

 - clearly every slice is psd.
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\mathcal{A}\in\mathbb{R}^{m\times m\times n}$
\end_inset

 is symmetric psd.
 
\begin_inset Formula $\star_{M}$
\end_inset

-CG to find a solution of 
\begin_inset Formula $\mathcal{A}\star_{M}\overline{X}=\overline{B}$
\end_inset


\end_layout

\begin_layout Algorithm*
pseudo-code defined in 
\color red

\begin_inset CommandInset citation
LatexCommand cite
key "article"
literal "false"

\end_inset


\color inherit
 for FFT:
\end_layout

\begin_layout Algorithm*
Input: tensor 
\begin_inset Formula $A\in\mathbb{R}^{p\times p\times n}$
\end_inset

, tensor 
\begin_inset Formula $b\in\mathbb{R}^{p\times1\times n}$
\end_inset

, matrix 
\begin_inset Formula $M\in\mathbb{R}^{n\times n}$
\end_inset


\end_layout

\begin_layout Algorithm*
Output: tensor 
\begin_inset Formula $x\in\mathbb{R}^{p\times1\times n}$
\end_inset

- solution of (2)
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{X}_{0}=zeros(p,1,n)$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $[\overline{D}_{0,}\gamma]=\overline{B}-\mathcal{A}\star\overline{X}_{0}$
\end_inset

 #normalization
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{R}_{0}=\overline{D}_{0}$
\end_inset


\end_layout

\begin_layout Algorithm*
for i in 1, ..., itermax:
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\alpha=(\overline{D}_{i-1}^{T}\star\mathcal{A}\star\overline{D}_{i-1})^{-1}\star(\overline{R}_{i-1}^{T}\star\overline{R}_{i-1})$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{X}_{i}=\overline{X}_{i-1}+\overline{R}_{i-1}\star\alpha$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{R}_{i}=\overline{R}_{i-1}-\mathcal{A}\star\overline{D}_{i-1}\star\alpha$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\beta=(\overline{R}_{i-1}^{T}\star\overline{R}_{i-1})^{-1}(\overline{R}_{i}^{T}\star\overline{R}_{i})$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{D}_{i}=\overline{R}_{i}+\overline{D}_{i-1}\star\beta$
\end_inset


\end_layout

\begin_layout Algorithm*
endfor
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{X}=\overline{X}\star\gamma$
\end_inset


\end_layout

\begin_layout Standard
where the normalization algorithm is following:
\end_layout

\begin_layout Algorithm*
Normalization of a vector tensor:
\end_layout

\begin_layout Algorithm*
Input: 
\begin_inset Formula $\overline{X}\in\mathbb{R}^{m\times1\times n}$
\end_inset

, matrix 
\begin_inset Formula $M\in\mathbb{R}^{n\times n}$
\end_inset


\end_layout

\begin_layout Algorithm*
Output: 
\begin_inset Formula $\overline{V}\in\mathbb{R}^{m\times1\times n},\alpha\in\mathbb{R}^{1\times1\times n}$
\end_inset

, s.t.
 
\begin_inset Formula $\overline{V}\star\alpha=\overline{X}$
\end_inset

 for not extreem cases and each vector slice of V: 
\begin_inset Formula $||\hat{V}_{i}||_{2}=1$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\hat{V}=\overline{X}\times_{3}M$
\end_inset


\end_layout

\begin_layout Algorithm*
for i in 1...n:
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\hat{\alpha}_{i}=||\hat{V}_{i}||_{2}$
\end_inset


\end_layout

\begin_layout Algorithm*
if 
\begin_inset Formula $\alpha_{i}<tol$
\end_inset

: 
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\hat{V}_{i}=randn(m,1)$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\hat{\alpha}_{i}=||\hat{V}_{i}||_{2}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\hat{V}_{i}=\hat{V}/\hat{\alpha}_{i},\hat{\alpha}=0$
\end_inset


\end_layout

\begin_layout Algorithm*
else: 
\begin_inset Formula $\hat{V}_{i}=\hat{V}/\hat{\alpha}_{i}$
\end_inset


\end_layout

\begin_layout Algorithm*
end for
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{V}=\hat{V}\times_{3}M^{-1}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\alpha=\hat{\alpha}\times_{3}M^{-1}$
\end_inset


\end_layout

\begin_layout Algorithm*
return 
\begin_inset Formula $[\overline{V},\alpha]=\overline{X}$
\end_inset


\end_layout

\begin_layout Definition
Krylov subspace of tensor 
\begin_inset Formula $\mathcal{A}$
\end_inset

 associated with 
\begin_inset Formula $\overline{D}$
\end_inset

 is 
\begin_inset Formula $\mathfrak{K}_{i}(\mathcal{A},\overline{D})=span(\overline{D},\mathcal{A}\star\overline{D},\mathcal{A}^{2}\star\overline{D},...,\mathcal{A}^{i}\star\overline{D})$
\end_inset

.
\end_layout

\begin_layout Standard
text
\end_layout

\begin_layout Definition
tubal scalar 
\begin_inset Formula $\nu_{{\cal A}}(\overline{E})=\overline{E}^{T}\star\mathcal{A}\star\overline{E}$
\end_inset

 is a tubal energy norm of 
\begin_inset Formula $\overline{E}$
\end_inset

.
 Energy norm of vector tensor 
\begin_inset Formula $\overline{E}$
\end_inset

 assosiated with tensor 
\begin_inset Formula ${\cal A}$
\end_inset

 is 
\begin_inset Formula $\left\Vert \overline{E}\right\Vert _{{\cal A}}\coloneqq\left\Vert \nu_{{\cal A}}\right\Vert _{F}$
\end_inset

.
\end_layout

\begin_layout Conjecture*
Let 
\begin_inset Formula $\Lambda({\cal \hat{A}}^{(i)})$
\end_inset

 denote set of all eigenvalues for frontal slice 
\begin_inset Formula ${\cal \hat{A}}^{(i)}$
\end_inset

, and let
\end_layout

\begin_layout Conjecture*
\begin_inset Formula $cond({\cal A})=max_{i}k_{i}$
\end_inset

 for 
\begin_inset Formula $k_{i}\in\Lambda({\cal \hat{A}}^{(i)})$
\end_inset


\begin_inset Formula $,\kappa_{i}=\frac{\max\Lambda({\cal \hat{A}}^{(i)})}{\min\Lambda({\cal {\cal \hat{A}}}^{(i)})}$
\end_inset

, note that each set 
\begin_inset Formula $\Lambda({\cal \hat{A}}^{(i)})$
\end_inset

 contains only positive elements for positive definite tensors.
 
\end_layout

\begin_layout Conjecture*
Denote 
\begin_inset Formula $\kappa$
\end_inset

 - tuple scalar with 
\begin_inset Formula $k_{i}$
\end_inset

 at slice i.
 Then elementwise:
\begin_inset Formula 
\[
\nu_{{\cal A}}(\overline{E}_{i})\leq2\left(\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}\right)^{i}\Delta\nu_{{\cal A}}(\overline{E}_{0}),
\]

\end_inset

and so
\begin_inset Formula 
\[
\left\Vert \overline{E}_{i}\right\Vert _{{\cal A}}\leq2\left(\frac{\sqrt{cond({\cal A})}-1}{\sqrt{cond({\cal A})}+1}\right)^{i}\cdot\left\Vert \overline{E}_{0}\right\Vert _{{\cal A}},
\]

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\overline{E}_{i}=\overline{X}_{i}-\overline{X}^{\star}$
\end_inset

- error of step i, 
\begin_inset Formula $\overline{R}_{i}=\overline{B}-\mathcal{A}\star_{M}\overline{X}_{i}=-\mathcal{A}\star_{M}\overline{E}_{i}$
\end_inset

- residual of step i
\end_layout

\begin_layout Proof
1) show that 
\begin_inset Formula $\overline{X_{i+1}}\in\overline{X_{0}}+\mathfrak{K}_{i}(\mathcal{A},\overline{R}_{0})$
\end_inset


\end_layout

\begin_layout Proof
2) then 
\begin_inset Formula $\overline{E}_{i}=\overline{E}_{0}+\mathfrak{K}_{i}(\mathcal{A},\overline{R}_{0})$
\end_inset

, since 
\begin_inset Formula $\overline{R}_{0}=-A\star_{M}\overline{E}_{0}$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\overline{E}_{i}=\overline{E}_{0}+span(A\star_{M}\overline{E}_{0},\mathcal{A}^{2}\star_{M}\overline{E}_{0},...,\mathcal{A}^{i}\star_{M}\overline{E}_{0})$
\end_inset


\end_layout

\begin_layout Proof
then 
\begin_inset Formula $\overline{E}_{i}=(\mathcal{I}+\sum_{j=1}^{i}\gamma_{j}\star A^{j})\star\overline{E}_{0}=P_{i}(\mathcal{A})\star\overline{E}_{0}$
\end_inset


\end_layout

\begin_layout Proof
Eigendecomposition of 
\begin_inset Formula $\mathcal{A}=\mathcal{V}\star\mathcal{D}\star\mathcal{V}^{-1}$
\end_inset


\end_layout

\begin_layout Proof
using eigenmatrices 
\begin_inset Formula $\overline{E}_{0}=\sum_{j=1}^{m}\xi_{j}\star\overline{V}_{j}$
\end_inset

, note that 
\begin_inset Formula $\mathcal{A}\star\overline{V}_{j}=\overline{V}\star\mathcal{D}_{jj}$
\end_inset


\end_layout

\begin_layout Proof
then 
\begin_inset Formula $\overline{E}_{i}=\sum_{j=1}^{m}P_{i}(\mathcal{D}_{jj})\star\xi_{j}\star\overline{V}_{j}$
\end_inset

, where 
\begin_inset Formula $P_{i}(\lambda)$
\end_inset

- polynom of degree i in a space of tuple scalars
\end_layout

\begin_layout Proof
then 
\begin_inset Formula $\nu_{{\cal A}}(\overline{E_{i}})=\sum_{j=1}^{m}P_{i}(\mathcal{D}_{jj})^{2}\star\xi_{j}^{2}\star\mathcal{D}_{jj}$
\end_inset

, in particular 
\begin_inset Formula $\nu_{{\cal A}}(\overline{E_{0}})=\sum_{j=1}^{m}\xi_{j}^{2}\star\mathcal{D}_{jj}$
\end_inset


\end_layout

\begin_layout Proof
lets prove a usefull poperty: for finite number of tuple scalars 
\begin_inset Formula $\alpha_{j},\beta_{j}$
\end_inset

 of depth 
\begin_inset Formula $n$
\end_inset

, s.t.
 
\begin_inset Formula $\hat{\alpha}_{j},\hat{\beta}_{j}>0$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\sum_{j}\alpha_{j}\star\beta_{j}\leq\alpha_{m}\Delta\sum_{j}b_{j}$
\end_inset

, where 
\begin_inset Formula $\alpha_{m}$
\end_inset

 is a tuple scalar, where each element at slice 
\begin_inset Formula $i$
\end_inset

 is 
\begin_inset Formula $max_{j}\alpha_{j}$
\end_inset

 for slice i.
\end_layout

\begin_layout Proof
reshape the tuple scalars to vector rows and write the expression in matrix
 form:
\end_layout

\begin_layout Proof
\begin_inset Formula $\sum_{j}\alpha_{j}\star\beta_{j}=(\sum_{j}\hat{a_{j}}\Delta\hat{b_{j}})M^{-1}\leq max_{j}\hat{\alpha_{j}}\Delta\sum_{j}\hat{b_{j}}M=max_{j}\hat{\alpha_{j}}\Delta\sum_{j}b_{j}$
\end_inset


\end_layout

\begin_layout Proof
since 
\begin_inset Formula $\hat{P_{i}(\mathcal{D}_{jj})^{2}}>0$
\end_inset

 and 
\begin_inset Formula $\hat{\xi_{j}^{2}\star\mathcal{D}_{jj}}>0,$
\end_inset

because 
\begin_inset Formula $\hat{\mathcal{D}_{jj}}>0$
\end_inset

 for PSD tensor 
\begin_inset Formula ${\cal A}$
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\|\overline{E}_{i}\|_{\mathcal{A}}\leq f(\mathcal{A})\Delta\|\overline{E}_{0}\|_{\mathcal{A}}$
\end_inset


\end_layout

\begin_layout Proof
where 
\begin_inset Formula $f(\mathcal{A})$
\end_inset

 is a tuple scalar, for eacah slice is 
\begin_inset Formula $f(\mathcal{A})^{(slice)}=min_{p_{i}}max_{d\in\Lambda(\hat{\mathcal{A}}^{(slice)})}p_{i}(d)$
\end_inset

, where 
\begin_inset Formula $p_{i}(d)$
\end_inset

- polynom of degree i in a space of scalars and 
\begin_inset Formula $\Lambda(\hat{\mathcal{A}}^{(slice)})$
\end_inset

 - set of all eigenvalues for frontal slice of 
\begin_inset Formula $\hat{\mathcal{A}}^{(slice)}$
\end_inset


\end_layout

\begin_layout Proof
the minimization can be done by Chebyshev polynomails and the expression
 is simplified to
\end_layout

\begin_layout Proof
\begin_inset Formula $\|\overline{E}_{i}\|_{\mathcal{A}}\leq2(\frac{\sqrt{cond({\cal A})}-1}{\sqrt{cond({\cal A})}+1})^{i}\|\overline{E}_{0}\|_{\mathcal{A}}$
\end_inset

.
\end_layout

\begin_layout Standard
numerical experiment complies with this statement, but maybe more tight
 bound can be found?
\end_layout

\begin_layout Subsection*
M-product LSQR
\end_layout

\begin_layout Standard
The algorithm was developed by 
\begin_inset CommandInset citation
LatexCommand cite
key "author"
literal "false"

\end_inset

 for DCT, where scalars are used for normalisation.
 I implemented the same algorithm, but with idea of normalization introduced
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "KilmerMartin11"
literal "false"

\end_inset

.
 The altered algorithm and numerical example, that demonstrates superiority
 is below
\end_layout

\begin_layout Standard
DONE: emphasize where the difference is between the algorithm in 
\begin_inset CommandInset citation
LatexCommand cite
key "author"
literal "false"

\end_inset

 and the algorithm you implemented.
\end_layout

\begin_layout Standard
Normalization in the algorithm in [author] is 
\begin_inset Formula $\beta=||\overline{B}||_{F}$
\end_inset

 (i.e.
 
\begin_inset Formula $\overline{U}=\overline{B}/\beta$
\end_inset

) - the normalisation is done over a norm of a whole tensor.
 Whereas by the suggested normalization in [KilmerMartin11] :
\end_layout

\begin_layout Standard
\begin_inset Formula $[\overline{U},\beta]=\overline{B}$
\end_inset

 - each slice is normalized separately in transformed space by M.
\end_layout

\begin_layout Standard
TODO (2): convergence result
\end_layout

\begin_layout Standard
denote by 
\begin_inset Formula ${\cal A}_{s}={\cal A}^{T}\star{\cal A}$
\end_inset

, then 
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\[
\left\Vert \overline{E}_{i}\right\Vert _{{\cal A}_{s}}\leq2\left(\frac{\sqrt{cond({\cal A}_{s}})-1}{\sqrt{cond({\cal A}_{s}})+1}\right)^{i}\cdot\left\Vert \overline{E}_{0}\right\Vert _{{\cal A}_{s}},
\]

\end_inset


\end_layout

\begin_layout Proof
show by induction that 
\begin_inset Formula $\overline{X_{i+1}}\in\overline{X_{0}}+\mathfrak{K}_{i}(\mathcal{A}_{s},\overline{R}_{0})$
\end_inset


\end_layout

\begin_layout Proof
and the following steps are identical to the prof of convergence for t-CG
 above.
\end_layout

\begin_layout Algorithm*
Input: tensor 
\begin_inset Formula ${\cal A}\in\mathbb{R}^{m\times p\times n}$
\end_inset

, tensor 
\begin_inset Formula $\overline{B}\in\mathbb{R}^{m\times1\times n}$
\end_inset


\end_layout

\begin_layout Algorithm*
Output: tensor 
\begin_inset Formula $x\in\mathbb{R}^{p\times1\times n}$
\end_inset

- minimisation solution
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{X}_{0}=zeros(p,1,n)$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $[\overline{U}_{0},\beta_{0}]=\overline{B}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $[\overline{V}_{0},\alpha_{0}]={\cal A}^{T}\star\overline{U}_{0}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{W}_{0}=\overline{V}_{0}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{\rho}_{0}=\alpha_{0},\overline{\phi}_{0}=\beta_{0}$
\end_inset


\end_layout

\begin_layout Algorithm*
for i in 1, ..., itermax:
\end_layout

\begin_layout Algorithm*
\begin_inset Formula $[\overline{U}_{i},\beta_{i}]={\cal A}\star\overline{V}_{i-1}-\overline{U}_{i-1}\star\alpha_{i-1}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $[\overline{V}_{i},\alpha_{i}]={\cal A}^{T}\star\overline{U}_{i}-\overline{V}_{i-1}\star\beta_{i}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\rho_{i}=(\sqrt{\hat{\overline{\rho}}_{i-1}^{2}+\hat{\beta}_{i}^{2}})\times_{3}M^{-1}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $c_{i}=\rho_{i}^{-1}\star\overline{\rho}_{i-1},s_{i}=\rho_{i}^{-1}\star\beta_{i}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\theta_{i}=s_{i}\star\alpha_{i},\overline{\rho}_{i}=c_{i}\star\alpha_{i}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\phi_{i}=c_{i}\star\overline{\phi}_{i-1},\overline{\phi}_{i}=-s_{i}\star\overline{\phi}_{i-1}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{X}_{i}=\overline{X}_{i-1}+\overline{W}_{i-1}\star\rho_{i}^{-1}\star\phi_{i}$
\end_inset


\end_layout

\begin_layout Algorithm*
\begin_inset Formula $\overline{W}_{i}=\overline{V}_{i-1}-\overline{W}_{i-1}\star\rho_{i}^{-1}\star\theta_{i}$
\end_inset


\end_layout

\begin_layout Algorithm*
endfor
\end_layout

\begin_layout Algorithm*

\color red
TODO (1): Normalize graphs.
\end_layout

\begin_layout Algorithm*
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_tuple.png
	lyxscale 60
	scale 40

\end_inset


\end_layout

\begin_layout Subsection*
M-product preconditioned LSQR
\end_layout

\begin_layout Standard
TODO (3) - add this (for matrices 
\begin_inset Formula $\|Ax-b\|_{2}$
\end_inset

 is transformed to 
\begin_inset Formula $\|AR^{-1}y-b\|_{2}$
\end_inset

 this is solved, and the we convert 
\begin_inset Formula $x=R^{-1}y$
\end_inset

).
\end_layout

\begin_layout Standard
Since the convergence depends on condition number of tensor 
\begin_inset Formula ${\cal A}$
\end_inset

, we want to transform the problem, s.t.
 condition number is small.
\end_layout

\begin_layout Standard
Denote 
\begin_inset Formula ${\cal A}_{p}={\cal A}\star{\cal P}$
\end_inset

, where 
\begin_inset Formula ${\cal P}$
\end_inset

is a preconditioning tensor, then by taking 
\begin_inset Formula $\overline{X}={\cal P}\star\overline{Y}$
\end_inset

, problem of minimization 
\begin_inset Formula $\|{\cal A}_{p}\star\overline{Y}-\overline{B}\|_{F}$
\end_inset

 is equivalent to the original problem.
\end_layout

\begin_layout Standard
We need to chose tensor 
\begin_inset Formula ${\cal P}$
\end_inset

, s.t.
 
\begin_inset Formula ${\cal A}_{p}$
\end_inset

 has small condition number.
 If 
\begin_inset Formula ${\cal P}\approx{\cal A}^{-1}$
\end_inset

, then 
\begin_inset Formula ${\cal A}_{p}\approx{\cal I}$
\end_inset

 and 
\begin_inset Formula $\kappa({\cal A})\approx1$
\end_inset


\end_layout

\begin_layout Section*
Numerical experiments.
\end_layout

\begin_layout Subsection*
Synthetic data
\end_layout

\begin_layout Standard
Construction of tensor 
\begin_inset Formula ${\cal A}$
\end_inset

:
\end_layout

\begin_layout Standard
A tall tensor 
\begin_inset Formula $\mathcal{A}\in\mathbb{R}^{m\times p\times2}$
\end_inset

, 
\begin_inset Formula ${\cal \hat{C}}=\hat{{\cal A}}^{T}\bigtriangleup\hat{{\cal A}}\in\mathbb{R}^{m\times p\times2}$
\end_inset


\end_layout

\begin_layout Standard
We construct a 'bad' tensor 
\begin_inset Formula ${\cal A}$
\end_inset

 s.t.
 eigenvalues of first slice of 
\begin_inset Formula ${\cal \hat{C}}$
\end_inset

 are between 1 and 2, whereas eigenvalues of second slice of 
\begin_inset Formula ${\cal \hat{C}}$
\end_inset

 are between 
\begin_inset Formula $1*10^{9}and2*10^{9}$
\end_inset

.
 In such a way each slice is well conditioned but the tensor condition number
 
\begin_inset Formula $k=\frac{d_{max}}{d_{min}}$
\end_inset

 is large.
\end_layout

\begin_layout Standard
let's denote a slice of 
\begin_inset Formula $\hat{{\cal A}}$
\end_inset

by matrix 
\begin_inset Formula $A$
\end_inset


\end_layout

\begin_layout Standard
then 
\begin_inset Formula $A^{T}A=Q\varLambda Q^{T}\Rightarrow Q^{T}A^{T}AQ=\varLambda,$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $A=PQ^{T}$
\end_inset

, where 
\begin_inset Formula $P^{T}P=\varLambda$
\end_inset


\end_layout

\begin_layout Standard
by chosing 
\begin_inset Formula $\varLambda$
\end_inset

 as needed, 
\begin_inset Formula $P=H[:,:p]\sqrt{\varLambda}$
\end_inset

, where 
\begin_inset Formula $H\in\mathbb{R}^{m\times m},Q\in\mathbb{R}^{p\times p}$
\end_inset

 - random orthogonal matrices, we obtain desired slice.
\end_layout

\begin_layout Standard
in the same way we create a 'good' tensor with all eigenvalues of both slices
 of 
\begin_inset Formula ${\cal C}$
\end_inset

are between 1 and 2.
\end_layout

\begin_layout Standard
to finish up the process we apply inverse of M to each tube.
\end_layout

\begin_layout Standard
error = 
\begin_inset Formula $\left\Vert \overline{E_{i}}\right\Vert _{{\cal A}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR.png
	scale 40

\end_inset


\end_layout

\begin_layout Standard
Experiment with 
\begin_inset Quotes eld
\end_inset

bad
\begin_inset Quotes erd
\end_inset

 tensor generated using M=DCT, and then doing regression with M=random.
 Should see Blue line behaving like yellow line.
 Reasoning: slowing doing of convergence due to 
\begin_inset Quotes eld
\end_inset

mismatch
\begin_inset Quotes erd
\end_inset

 between frontal slices in transform domain is for very special M (i.e.
 the dataset is chosen advesarily for the M or M chosen advesarily for the
 given dataset).
 But if we take a fixed dataset and chose M randomaly, we should be OK.
 Then choosing a random M can be viewed as a form of preconditioning.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_trans_dct.png
	scale 40

\end_inset


\end_layout

\begin_layout Subsection*
Tensor Blendenpik
\end_layout

\begin_layout Standard
Inputs: 
\begin_inset Formula $\mathcal{A}\in\mathbb{R}^{m\times p\times n}$
\end_inset

, 
\begin_inset Formula $\overline{B}\in\mathbb{R}^{m\times1\times n}$
\end_inset


\end_layout

\begin_layout Enumerate
Generate a random 
\begin_inset Formula ${\cal S}\in\mathbb{R}^{s\times m\times n}$
\end_inset

 with iid 
\begin_inset Formula $N(0,1)$
\end_inset

.
 
\begin_inset Formula $s$
\end_inset

 is a parameter.
 (note that 
\begin_inset Formula $\hat{{\cal S}}$
\end_inset

 has same distribution as 
\begin_inset Formula ${\cal S}$
\end_inset

)
\end_layout

\begin_layout Enumerate
Compute 
\begin_inset Formula ${\cal W}={\cal S}\star_{M}{\cal A}$
\end_inset


\end_layout

\begin_layout Enumerate
Factorize 
\begin_inset Formula ${\cal W}={\cal Q}\star_{M}{\cal R}$
\end_inset


\end_layout

\begin_layout Enumerate
Solve the problem using t-LSQR with 
\begin_inset Formula ${\cal R}$
\end_inset

 as preconditioner.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
DONE: Plot vs iteration 
\begin_inset Formula $\|{\cal A^{T}}\star_{M}({\cal A}\star_{M}\bar{X}-\bar{B})\|_{F}/(\|{\cal A}\|_{F}\cdot\|{\cal A}\star_{M}\bar{X}-\bar{B}\|_{F})$
\end_inset


\end_layout

\begin_layout Standard
condition number=100
\end_layout

\begin_layout Standard

\color red
TODO (2): Generate an additional graph, where 
\begin_inset Formula $\bar{B}$
\end_inset

 is generated randomly 
\begin_inset Formula $N(0,1)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_sample_500_50_sampl300_k100_normalized_residual_B.png
	scale 20

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_sample_500_50_sampl300_k100_residual_B.png
	scale 20

\end_inset


\end_layout

\begin_layout Standard

\color red
TODO (3): Test with larger 
\begin_inset Formula $n$
\end_inset

 (
\begin_inset Formula $n\gg500)$
\end_inset

 and condition number much larger (
\begin_inset Formula $10^{6}$
\end_inset

).
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\color red
TODO (4): Look at the experiments in the Blendenpik paper, and think how
 to 
\begin_inset Quotes eld
\end_inset

translate
\begin_inset Quotes erd
\end_inset

 them for the tensor case.
\end_layout

\begin_layout Standard

\color red
TODO (5): Explain in notes how you use 
\begin_inset Formula $S$
\end_inset

 that is base on randomized DCT.
 Do complexity analysis of both normal 
\begin_inset Formula $S$
\end_inset

 and DCT based 
\begin_inset Formula $S$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_sample_300_k100_res_norm.png
	scale 40

\end_inset


\end_layout

\begin_layout Standard
and 
\begin_inset Formula $\|{\cal A}\star_{M}\bar{X}-\bar{B}\|_{F}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_sample_300_k100_res.png
	scale 40

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_sample_300_k100.png
	scale 40

\end_inset


\end_layout

\begin_layout Standard
small condition number=2
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_blendenpik_300_res_norm.png
	scale 40

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename eigenvalues_experiment_LSQR_sample_300_k2_res.png
	scale 40

\end_inset


\end_layout

\begin_layout Subsection*
Realistic Dataset for Regression
\end_layout

\begin_layout Standard
Haim
\end_layout

\begin_layout Standard
code: https://github.com/AnnPike/thesis/tree/blendenpik_precond_inside_LSQR
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "starM"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
